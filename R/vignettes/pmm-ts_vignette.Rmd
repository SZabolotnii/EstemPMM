---
title: "Моделювання часових рядів методом поліноміальної максимізації (PMM)"
author: "Пакет EstemPMM"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Моделювання часових рядів методом поліноміальної максимізації (PMM)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

## Вступ

Метод поліноміальної максимізації (Polynomial Maximization Method, PMM) - це підхід до оцінювання параметрів, який особливо ефективний для даних з негаусівським розподілом. Пакет `EstemPMM` розширює цей метод на моделі часових рядів, включаючи:

-   AR (авторегресійні моделі)
-   MA (моделі ковзного середнього)
-   ARMA (авторегресійні моделі ковзного середнього)
-   ARIMA (інтегровані авторегресійні моделі ковзного середнього)

У цій віньєтці ми покажемо, як використовувати PMM2 (PMM другого порядку) для оцінювання параметрів цих моделей, особливо коли інновації (похибки) мають негаусівський розподіл.

```{r setup}
library(EstemPMM)
```

## Теоретичні основи PMM для часових рядів

PMM заснований на ідеї максимізації стохастичного полінома, який враховує статистики більш високих порядків (моменти або кумулянти). На відміну від методу максимальної правдоподібності (MML), який вимагає повного знання розподілу, PMM використовує обмежену кількість статистик, що робить його більш гнучким і обчислювально ефективним.

PMM2 використовує статистики до 4-го порядку (дисперсія, асиметрія, ексцес) для оцінки параметрів моделей. Теоретично було показано, що відношення дисперсій оцінок PMM2 до класичних оцінок (наприклад, методом найменших квадратів) визначається формулою:

$g^2 = 1 - \frac{\gamma_3^2}{2 + \gamma_4}$

де $\gamma_3$ - коефіцієнт асиметрії, а $\gamma_4$ - коефіцієнт ексцесу інновацій.

Коли розподіл інновацій відхиляється від нормального (особливо при наявності асиметрії), PMM2 може давати значно менші дисперсії оцінок, що робить цей метод більш ефективним.

## Моделювання AR процесів

Авторегресійна модель порядку p (AR(p)) виражається як:

$X_t = a_0 + a_1 X_{t-1} + a_2 X_{t-2} + ... + a_p X_{t-p} + \epsilon_t$

де $\epsilon_t$ - інновації (білий шум), які можуть мати негаусівський розподіл.

### Приклад AR(2) з t-розподілом

Розглянемо AR(2) процес з інноваціями, що мають розподіл Стьюдента (t-розподіл), який має важчі хвости ніж нормальний розподіл:

```{r ar-example}
# Встановлення seed для відтворюваності
set.seed(123)

# Генерація AR(2) процесу з t-розподілом (df=3)
ar_coef <- c(0.7, -0.3)
n <- 300
ar_series <- arima.sim(model = list(ar = ar_coef), n = n, 
                       rand.gen = function(n) rt(n, df=3))

# Графік ряду
plot(ar_series, type = "l", main = "AR(2) з t-розподілом інновацій")
```

Тепер порівняємо результати оцінювання параметрів за допомогою різних методів:

```{r ar-comparison}
# Порівняння методів
ar_comparison <- compare_ar_methods(ar_series, order = 2)

# Таблиця коефіцієнтів
knitr::kable(ar_comparison$coefficients, 
             caption = "Порівняння оцінок коефіцієнтів AR(2) моделі")

# Статистика залишків
knitr::kable(ar_comparison$residual_stats, 
             caption = "Порівняння статистики залишків")
```

Як бачимо, PMM2 дає оцінки, які близькі до true значень (`r ar_coef`), але має кращі показники залишків (менші RSS і MAE).

Діагностичні графіки для PMM2-моделі:

```{r ar-plots, fig.width=8, fig.height=6}
# Діагностичні графіки
par(mfrow=c(2,2))
plot(ar_comparison$pmm2, main="AR-PMM2 діагностичні графіки")
```

## Моделювання MA процесів

Модель ковзного середнього порядку q (MA(q)) виражається як:

$X_t = \epsilon_t + b_1 \epsilon_{t-1} + b_2 \epsilon_{t-2} + ... + b_q \epsilon_{t-q}$

### Приклад MA(2) з гамма-розподілом

Розглянемо MA(2) процес з інноваціями, що мають гамма-розподіл, який є асиметричним:

```{r ma-example}
# Встановлення seed для відтворюваності
set.seed(456)

# Генерація MA(2) процесу з гамма-розподілом
ma_coef <- c(0.6, -0.2)
gamma_innov <- rgamma(n, shape=2, scale=1) - 2  # центруємо для нульового середнього
ma_series <- filter(gamma_innov, ma_coef, method="convolution", sides=1)
ma_series[is.na(ma_series)] <- 0  # Заміна NA на початку ряду

# Графік ряду
plot(ma_series, type = "l", main = "MA(2) з гамма-розподілом інновацій")
```

Порівняємо результати оцінювання:

```{r ma-comparison}
# Порівняння методів
ma_comparison <- compare_ma_methods(ma_series, order = 2)

# Таблиця коефіцієнтів
knitr::kable(ma_comparison$coefficients, 
             caption = "Порівняння оцінок коефіцієнтів MA(2) моделі")

# Статистика залишків
knitr::kable(ma_comparison$residual_stats, 
             caption = "Порівняння статистики залишків")
```

Діагностичні графіки для MA-PMM2 моделі:

```{r ma-plots, fig.width=8, fig.height=6}
# Діагностичні графіки
par(mfrow=c(2,2))
plot(ma_comparison$pmm2, main="MA-PMM2 діагностичні графіки")
```

## Моделювання ARMA процесів

ARMA(p,q) моделі комбінують авторегресійні компоненти та компоненти ковзного середнього:

$X_t = a_0 + a_1 X_{t-1} + ... + a_p X_{t-p} + \epsilon_t + b_1 \epsilon_{t-1} + ... + b_q \epsilon_{t-q}$

### Приклад ARMA(1,1) з сумішшю нормальних розподілів

```{r arma-example}
# Встановлення seed для відтворюваності
set.seed(789)

# Генерація інновацій як суміш двох нормальних розподілів
n <- 300
mix_innov <- numeric(n)
for(i in 1:n) {
  # 70% з N(0,1) та 30% з N(3,2)
  mix_innov[i] <- ifelse(runif(1) < 0.7, rnorm(1), rnorm(1, mean=3, sd=2))
}
# Центруємо для нульового середнього
mix_innov <- mix_innov - mean(mix_innov)

# Створюємо ARMA серію
arma_series <- arima.sim(model = list(ar = 0.7, ma = 0.4), n = n, 
                         innov = mix_innov)

# Графік ряду
plot(arma_series, type = "l", main = "ARMA(1,1) з сумішшю нормальних розподілів")
```

Порівняємо результати:

```{r arma-comparison}
# Порівняння методів
arma_comparison <- compare_arma_methods(arma_series, order = c(1, 1))

# Таблиця коефіцієнтів
knitr::kable(arma_comparison$coefficients, 
             caption = "Порівняння оцінок коефіцієнтів ARMA(1,1) моделі")

# Статистика залишків
knitr::kable(arma_comparison$residual_stats, 
             caption = "Порівняння статистики залишків")
```

Діагностичні графіки:

```{r arma-plots, fig.width=8, fig.height=6}
# Діагностичні графіки
par(mfrow=c(2,2))
plot(arma_comparison$pmm2, main="ARMA-PMM2 діагностичні графіки")
```

## Моделювання ARIMA процесів

ARIMA(p,d,q) моделі розширюють ARMA моделі, додаючи d-разове диференціювання для роботи з нестаціонарними часовими рядами:

$\Delta^d X_t = a_0 + a_1 \Delta^d X_{t-1} + ... + a_p \Delta^d X_{t-p} + \epsilon_t + b_1 \epsilon_{t-1} + ... + b_q \epsilon_{t-q}$

де $\Delta^d$ - оператор d-разового диференціювання.

### Приклад ARIMA(1,1,1) з асиметричним розподілом

```{r arima-example}
# Встановлення seed для відтворюваності
set.seed(101)

# Генерація ARMA серії з асиметричними похибками
arma_base <- arima.sim(model = list(ar = 0.7, ma = 0.4), n = n, 
                      rand.gen = function(n) rgamma(n, shape=2, scale=1) - 2)

# Перетворюємо в нестаціонарний ряд через інтегрування (кумулятивну суму)
arima_series <- cumsum(arma_base)

# Графік ряду
plot(arima_series, type = "l", main = "ARIMA(1,1,1) серія")
```

Порівняємо результати:

```{r arima-comparison}
# Порівняння методів
arima_comparison <- compare_arima_methods(arima_series, order = c(1, 1, 1))

# Таблиця коефіцієнтів
knitr::kable(arima_comparison$coefficients, 
             caption = "Порівняння оцінок коефіцієнтів ARIMA(1,1,1) моделі")

# Статистика залишків
knitr::kable(arima_comparison$residual_stats, 
             caption = "Порівняння статистики залишків")
```

Діагностичні графіки:

```{r arima-plots, fig.width=10, fig.height=8}
# Діагностичні графіки
par(mfrow=c(3,2))
plot(arima_comparison$pmm2, main="ARIMA-PMM2 діагностичні графіки", which=1:6)
```

## Прогнозування

Функції PMM2 для часових рядів підтримують прогнозування за допомогою методу `predict`:

```{r prediction}
# AR прогноз
ar_forecast <- predict(ar_comparison$pmm2, n.ahead = 10)
cat("AR(2) прогноз на 10 кроків вперед:\n")
print(ar_forecast)

# ARIMA прогноз
arima_forecast <- predict(arima_comparison$pmm2, n.ahead = 10)
cat("\nARIMA(1,1,1) прогноз на 10 кроків вперед:\n")
print(arima_forecast$pred)
```

## Ефективність PMM2 в залежності від асиметрії та ексцесу

Теоретично доведено, що відношення дисперсій оцінок PMM2 до класичних оцінок ($g^2$) залежить від коефіцієнтів асиметрії ($\gamma_3$) та ексцесу ($\gamma_4$) розподілу інновацій:

$g^2 = 1 - \frac{\gamma_3^2}{2 + \gamma_4}$

Візуалізуємо цю залежність:

```{r efficiency-plot, fig.width=10, fig.height=7}
# Створення сітки значень асиметрії та ексцесу
skewness_values <- seq(0, 2, by=0.2)  # від 0 до 2
kurtosis_values <- seq(0, 6, by=0.5)   # від 0 до 6

# Обчислення коефіцієнту ефективності PMM2
g2_values <- matrix(0, length(skewness_values), length(kurtosis_values))

for(i in 1:length(skewness_values)) {
  for(j in 1:length(kurtosis_values)) {
    g2 <- 1 - (skewness_values[i]^2) / (2 + kurtosis_values[j])
    # Обмежимо значення від 0 до 1
    g2_values[i, j] <- max(0, min(1, g2))
  }
}

# Візуалізація залежності
filled.contour(
  skewness_values, 
  kurtosis_values, 
  g2_values,
  color.palette = colorRampPalette(c("red", "yellow", "green")),
  xlab = "Асиметрія (γ₃)", 
  ylab = "Ексцес (γ₄)",
  main = "Співвідношення варіацій PMM2 до класичних оцінок (g²)",
  key.title = title("g²")
)

# Додаємо лінію, що відповідає рівності γ₄ + 2 = γ₃²
contour(skewness_values, kurtosis_values, 
        outer(skewness_values^2, rep(1, length(kurtosis_values))) - 
          outer(rep(1, length(skewness_values)), kurtosis_values) - 2,
        levels = 0, add = TRUE, lwd = 2, col = "black", lty = 2)

# Додаємо легенду
legend("topright", 
       legend = "γ₄ + 2 = γ₃² (теоретична межа)",
       lty = 2, 
       col = "black", 
       lwd = 2,
       bg = "white")
```

На графіку: - Зелений колір означає високу ефективність PMM2 (мала дисперсія оцінок) - Червоний колір означає ефективність близьку до класичних методів - Пунктирна лінія показує теоретичну межу для можливих комбінацій асиметрії та ексцесу

Ефективність PMM2 зростає зі збільшенням асиметрії розподілу та зменшенням ексцесу. Це узгоджується з теоретичними результатами.

## Висновки

Метод поліноміальної максимізації (PMM2) є потужним інструментом для оцінювання параметрів моделей часових рядів з негаусівськими інноваціями. Він особливо ефективний для даних з асиметричними розподілами, де класичні методи (LS, CSS, ML) можуть давати менш ефективні оцінки.

Пакет `EstemPMM` надає зручний інтерфейс для використання PMM2 з AR, MA, ARMA та ARIMA моделями, а також функції для порівняння результатів різних методів оцінювання.
